{
  "cells": [
    {
      "metadata": {
        "id": "unique-main-intro-md"
      },
      "cell_type": "markdown",
      "source": [
        "# Magenta RT ile İnce Ayar (Fine-tuning)\n",
        "\n",
        "**Hoş Geldiniz!** Bu Colab not defteri, Magenta RT müzik üretim modelini kendi ses verilerinizle ince ayar yapmanıza yardımcı olmak için tasarlanmıştır. İnce ayar, önceden eğitilmiş bir modeli alıp kendi özel veri kümeniz üzerinde ek eğitim yaparak modelin davranışını veri kümenizin özelliklerine (örneğin, belirli bir müzik stili) daha iyi uyacak şekilde adapte etme sürecidir.\n",
        "\n",
        "**Bu Not Defteri Ne Yapar (Kavramsal Düzeyde):**\n",
        "1.  **Kurulum:** Gerekli kütüphaneleri ve Magenta RT modelini yükler.\n",
        "2.  **Veri Yükleme:** İnce ayar için kendi ses dosyalarınızı yüklemenize olanak tanır.\n",
        "3.  **Veri Ön İşleme:** Yüklediğiniz ses dosyalarını modelin anlayabileceği bir formata (ses belirteçleri) dönüştürür.\n",
        "4.  **Model ve Optimizatör Tanımlama (Kavramsal):** İnce ayar yapılacak model bileşenlerini ve eğitim için kullanılacak optimizasyon araçlarını tanımlar.\n",
        "5.  **Eğitim Döngüsü (Kavramsal):** Modelin kendi verileriniz üzerinde eğitilmesini sağlar.\n",
        "6.  **Modeli Kaydetme (Kavramsal):** İnce ayarlanmış modelinizi daha sonra kullanmak üzere kaydetmenize olanak tanır.\n",
        "\n",
        "**ÖNEMLİ UYARILAR:**\n",
        "*   **TPU Gereksinimi:** Bu not defteri, verimli bir şekilde çalışmak için bir **TPU çalışma zamanı** gerektirir (`Runtime > Change Runtime Type > TPU`).\n",
        "*   **Deneysel Özellik:** Magenta RT için kullanıcı dostu ince ayar araçları aktif olarak geliştirilmektedir. Bu not defteri, sürecin **kavramsal bir uygulamasını** sunar. Özellikle Model Tanımlama (Adım 4) ve Eğitim Döngüsü (Adım 5) adımları, Magenta RT'nin altında yatan T5X modelinin karmaşık yapısı nedeniyle basitleştirilmiş veya yer tutucu kodlar içerebilir. Gerçek bir ince ayar, T5X'in kendi eğitim altyapısının daha derinlemesine entegrasyonunu gerektirebilir.\n",
        "*   **Kaynak ve Zaman:** İnce ayar, veri kümenizin boyutuna ve seçtiğiniz eğitim parametrelerine bağlı olarak önemli miktarda zaman ve hesaplama kaynağı (özellikle TPU kullanımı) tüketebilir.\n",
        "*   **Veri Hazırlığı:** Başlamadan önce, ince ayar için kullanacağınız ses dosyalarını (tercihen `.wav` formatında, hedef stile uygun, çeşitli ve kısa müzik parçaları) hazırlamanız önemlidir.\n",
        "\n",
        "Lütfen her adımı dikkatlice okuyun ve talimatları izleyin. Başarılar!"
      ]
    },
    {
      "metadata": {
        "id": "unique-setup-md"
      },
      "cell_type": "markdown",
      "source": [
        "## Adım 1: Kurulum ve Gerekli Bileşenlerin Başlatılması\n",
        "\n",
        "Bu ilk adımda, Magenta RT kütüphanesini ve bağımlılıklarını yükleyip, ince ayar için temel alınacak olan önceden eğitilmiş Magenta RT modelini (ve ilişkili kodekleri) başlatacağız."
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "unique-install-code"
      },
      "cell_type": "code",
      "source": [
        "# @title **Bu hücreyi çalıştırın** bağımlılıkları yüklemek için (~5 dakika)\n",
        "# @markdown TPU çalışma zamanı kullandığınızdan emin olun (`Runtime > Change Runtime Type`).\n",
        "\n",
        "# @markdown Colab, oturumu yeniden başlatmanızı isteyebilir. **Yeniden başlatmadan önce hücrenin çalışmasının bitmesini bekleyin!** Oturum yeniden başlatıldıktan sonra bir sonraki hücreye geçin.\n",
        "\n",
        "print(\"Magenta RealTime deposu klonlanıyor...\")\n",
        "!git clone https://github.com/magenta/magenta-realtime.git\n",
        "\n",
        "print(\"Gerekli TensorFlow sürümleri ayarlanıyor...\")\n",
        "# Magenta RT, TF nightly yapılarını gerektirir.\n",
        "_all_tf = 'tensorflow tf-nightly tensorflow-cpu tf-nightly-cpu tensorflow-tpu tf-nightly-tpu tensorflow-hub tf-hub-nightly tensorflow-text tensorflow-text-nightly'\n",
        "_nightly_tf = 'tf-nightly tensorflow-text-nightly tf-hub-nightly'\n",
        "\n",
        "print(\"Kütüphane ve bağımlılıklar yükleniyor (TPU için)...\")\n",
        "!pip install -e magenta-realtime/[tpu] && pip uninstall -y {_all_tf} && pip install {_nightly_tf}\n",
        "\n",
        "print(\"Kurulum tamamlandı. Eğer Colab tarafından istendiyse, şimdi 'Runtime > Restart Session' menüsünden oturumu yeniden başlatın ve bir sonraki hücreyle devam edin.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "unique-init-model-code"
      },
      "cell_type": "code",
      "source": [
        "# @title **Oturumu yeniden başlattıysanız bu hücreyi çalıştırın** modeli ve diğer bileşenleri başlatmak için.\n",
        "# @markdown Modelin ilk kez yüklenmesi (kontrol noktalarının indirilmesi) biraz zaman alabilir.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf # Tensorflow importu, TF nightly'nin düzgün yüklendiğini doğrulamak için de iyidir.\n",
        "\n",
        "print(f\"TensorFlow sürümü: {tf.__version__}\")\n",
        "print(\"Gerekli modüller yükleniyor...\")\n",
        "from magenta_rt import system\n",
        "from magenta_rt import audio\n",
        "from magenta_rt import musiccoca # MusicCoCa'nın da yüklenmesi gerekebilir, ancak ince ayarda doğrudan kullanılmayacak.\n",
        "from magenta_rt import spectrostream\n",
        "from magenta_rt.colab import utils # Demo Colab'daki rvq_to_llm vb. için\n",
        "from google.colab import files\n",
        "import librosa\n",
        "import tarfile\n",
        "import io # zipfile için gerekebilir\n",
        "import zipfile # zip dosyalarını açmak için\n",
        "\n",
        "print(\"Magenta RT modeli yükleniyor (lazy=True)...\")\n",
        "# Modeli lazy=True ile yüklüyoruz, böylece hemen belleğe alınmaz.\n",
        "# İnce ayar için genellikle 'büyük' model tercih edilir, ancak kaynaklara göre 'base' de denenebilir.\n",
        "MODEL_TAG = \"large\" #@param [\"base\", \"large\"]\n",
        "MRT = None\n",
        "codec = None # codec'i global yapmak için\n",
        "try:\n",
        "  MRT = system.MagentaRT(\n",
        "      tag=MODEL_TAG, device=\"tpu:v2-8\", skip_cache=True, lazy=True\n",
        "  )\n",
        "  print(f\"Magenta RT '{MODEL_TAG}' modeli başarıyla yüklendi (veya yüklenecek şekilde ayarlandı).\")\n",
        "  # SpectroStream kodeğini alalım, veri ön işleme için gerekecek.\n",
        "  codec = MRT.codec\n",
        "  # Modelin kendisini (LLM) daha sonra `MRT._llm` ile alacağız, ancak bu nesnenin \n",
        "  # doğrudan eğitilebilir olup olmadığı veya T5X değişkenlerine nasıl erişileceği incelenmelidir.\n",
        "  print(\"SpectroStream kodeği başarıyla alındı.\")\n",
        "except Exception as e:\n",
        "  print(f\"Model yüklenirken bir hata oluştu: {e}\")\n",
        "  print(\"Lütfen çalışma zamanının TPU olarak ayarlandığından ve önceki hücrenin başarıyla çalıştırıldığından emin olun.\")\n",
        "\n",
        "print(\"Başlatma ve hazırlık adımı tamamlandı.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "unique-data-upload-md"
      },
      "cell_type": "markdown",
      "source": [
        "## Adım 2: İnce Ayar Verilerini Yükleme\n",
        "\n",
        "Bu adımda, Magenta RT modelini ince ayar yapmak için kullanacağınız kendi ses dosyalarınızı yükleyeceksiniz.\n",
        "\n",
        "**Desteklenen Formatlar:**\n",
        "*   `.wav`\n",
        "*   `.mp3`\n",
        "*   `.zip` (içinde `.wav` veya `.mp3` dosyaları bulunan bir arşiv)\n",
        "\n",
        "**Öneriler:**\n",
        "*   **Kalite ve Çeşitlilik:** İnce ayar için yüksek kaliteli, çeşitli ve hedeflediğiniz stile uygun ses dosyaları kullanın. Model, verdiğiniz verinin özelliklerini öğrenmeye çalışacaktır.\n",
        "*   **Dosya Uzunluğu:** Dosyalar çok uzun olmamalıdır (örneğin, her biri birkaç saniye ile bir dakika arasında). Daha uzun dosyalar bir sonraki adımda otomatik olarak daha kısa parçalara ayrılacaktır.\n",
        "*   **Miktar:** Daha fazla veri genellikle daha iyi sonuçlar verir, ancak Colab'ın kaynak sınırlarını ve işlem süresini de göz önünde bulundurun.\n",
        "*   **ZIP Kullanımı:** Çok sayıda dosya yükleyecekseniz, bunları tek bir ZIP arşivinde birleştirmek ve yüklemek daha pratiktir."
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "unique-upload-files-code"
      },
      "cell_type": "code",
      "source": [
        "# @title Veri Yükleme Hücresi\n",
        "\n",
        "UPLOAD_METHOD = \"Dosya Yükle\" #@param [\"Dosya Yükle\", \"Google Drive'dan Bağla\"]\n",
        "#@markdown Ses dosyalarınızın yükleneceği veya bulunacağı geçici dizin:\n",
        "UPLOAD_PATH = \"fine_tuning_data/uploaded/\" #@param {type:\"string\"}\n",
        "#@markdown --- \n",
        "#@markdown **\"Dosya Yükle\"** seçeneği için:\n",
        "#@markdown Bu hücreyi çalıştırdıktan sonra \"Dosya Seç\" düğmesi görünecektir. Birden fazla dosya veya bir ZIP dosyası seçebilirsiniz.\n",
        "#@markdown --- \n",
        "#@markdown **\"Google Drive'dan Bağla\"** seçeneği için:\n",
        "#@markdown Google Drive'ınızdaki ses dosyalarını içeren klasörün yolunu belirtin (örneğin, `/MyDrive/my_music_data/`).\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/fine_tuning_audio/\" #@param {type:\"string\"}\n",
        "\n",
        "if not os.path.exists(UPLOAD_PATH):\n",
        "  os.makedirs(UPLOAD_PATH)\n",
        "  print(f\"'{UPLOAD_PATH}' dizini oluşturuldu.\")\n",
        "\n",
        "uploaded_file_paths = [] # Yüklenen veya Drive'dan bulunan dosyaların ilk listesi\n",
        "\n",
        "if UPLOAD_METHOD == \"Dosya Yükle\":\n",
        "  print(f\"Lütfen ince ayar için ses dosyalarınızı (veya .zip dosyanızı) seçin.\")\n",
        "  try:\n",
        "    # Birden fazla dosya yüklemeye izin vermek için files.upload() çağrısını döngü dışında tutun\n",
        "    uploaded_files_dict = files.upload()\n",
        "    if not uploaded_files_dict:\n",
        "        print(\"Hiç dosya seçilmedi.\")\n",
        "    else:\n",
        "        for filename, data in uploaded_files_dict.items():\n",
        "          filepath = os.path.join(UPLOAD_PATH, filename)\n",
        "          with open(filepath, 'wb') as f:\n",
        "            f.write(data)\n",
        "          print(f\"'{filename}' dosyası '{filepath}' olarak kaydedildi.\")\n",
        "          uploaded_file_paths.append(filepath)\n",
        "  except Exception as e:\n",
        "    # 'NotFoundError' genellikle kullanıcı 'Cancel' düğmesine bastığında oluşur.\n",
        "    if 'NotFoundError' in str(e) or 'No files were selected' in str(e):\n",
        "      print(\"Dosya yükleme işlemi iptal edildi veya hiç dosya seçilmedi.\")\n",
        "    else:\n",
        "      print(f\"Dosya yüklenirken bir hata oluştu: {e}\")\n",
        "elif UPLOAD_METHOD == \"Google Drive'dan Bağla\":\n",
        "  from google.colab import drive\n",
        "  try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(f\"Google Drive başarıyla bağlandı.\")\n",
        "    actual_drive_path = DRIVE_PATH.strip()\n",
        "    if os.path.exists(actual_drive_path):\n",
        "      print(f\"Google Drive'daki '{actual_drive_path}' içeriği taranıyor...\")\n",
        "      # Bu demoda, DRIVE_PATH'teki dosyaları doğrudan işleyeceğiz.\n",
        "      # Bu nedenle UPLOAD_PATH'i DRIVE_PATH olarak ayarlıyoruz.\n",
        "      UPLOAD_PATH = actual_drive_path \n",
        "      for dirname, _, filenames in os.walk(actual_drive_path):\n",
        "        for filename in filenames:\n",
        "          if filename.lower().endswith(('.wav', '.mp3', '.zip')):\n",
        "            filepath = os.path.join(dirname, filename)\n",
        "            uploaded_file_paths.append(filepath)\n",
        "      if uploaded_file_paths:\n",
        "        print(f\"{len(uploaded_file_paths)} adet potansiyel dosya bulundu.\")\n",
        "      else:\n",
        "        print(f\"'{actual_drive_path}' içinde desteklenen formatta dosya bulunamadı (.wav, .mp3, .zip).\")\n",
        "    else:\n",
        "      print(f\"HATA: Google Drive'da belirtilen '{actual_drive_path}' yolu bulunamadı. Lütfen yolu kontrol edin.\")\n",
        "  except Exception as e:\n",
        "    print(f\"Google Drive bağlanırken bir hata oluştu: {e}\")\n",
        "\n",
        "if uploaded_file_paths:\n",
        "  print(\"\\nYüklenen ve/veya Google Drive'dan bulunan dosyaların listesi:\")\n",
        "  for p in uploaded_file_paths:\n",
        "    print(f\"  - {p}\")\n",
        "else:\n",
        "  print(\"\\nHiçbir dosya yüklenmedi veya belirtilen Google Drive yolunda bulunamadı.\")\n",
        "\n",
        "# ZIP dosyalarını açma (eğer varsa)\n",
        "extracted_audio_files = []\n",
        "if uploaded_file_paths:\n",
        "  print(\"\\nZIP dosyaları (varsa) ayıklanıyor...\")\n",
        "  # ZIP'ten çıkan dosyalar için ayrı bir alt dizin oluşturalım, karışmasın.\n",
        "  # Eğer UPLOAD_PATH Google Drive ise, Drive'a yazmamak için yerel bir path kullanalım.\n",
        "  zip_extract_base = \"fine_tuning_data/extracted/\" if UPLOAD_METHOD == \"Dosya Yükle\" else os.path.join(UPLOAD_PATH, \"extracted_from_zip\")\n",
        "  if not os.path.exists(zip_extract_base):\n",
        "      os.makedirs(zip_extract_base)\n",
        "\n",
        "  processed_any_zip = False\n",
        "  for filepath in uploaded_file_paths:\n",
        "    if filepath.lower().endswith('.zip'):\n",
        "      processed_any_zip = True\n",
        "      print(f\"  '{filepath}' ZIP dosyası işleniyor...\")\n",
        "      try:\n",
        "        with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "            zip_ref.extractall(zip_extract_base)\n",
        "            print(f\"    '{filepath}' içeriği '{zip_extract_base}' dizinine başarıyla ayıklandı.\")\n",
        "            # Ayıklanan dosyaları listeye ekle\n",
        "            for member in zip_ref.namelist():\n",
        "                if member.lower().endswith(('.wav', '.mp3')) and not member.startswith('__MACOSX'): # MAC OSX'in ürettiği gereksiz dosyaları atla\n",
        "                    extracted_audio_files.append(os.path.join(zip_extract_base, member))\n",
        "      except zipfile.BadZipFile:\n",
        "        print(f\"    HATA: '{filepath}' geçerli bir ZIP dosyası değil veya bozuk.\")\n",
        "      except Exception as e:\n",
        "        print(f\"    HATA: '{filepath}' ZIP dosyası ayıklanırken bir sorun oluştu: {e}\")\n",
        "    elif filepath.lower().endswith(('.wav', '.mp3')):\n",
        "      # Doğrudan yüklenen (veya Drive'da bulunan) WAV/MP3 dosyalarını da listeye ekle\n",
        "      extracted_audio_files.append(filepath)\n",
        "  \n",
        "  if not processed_any_zip:\n",
        "      print(\"İşlenecek ZIP dosyası bulunamadı.\")\n",
        "\n",
        "# Tekrarları kaldır ve son listeyi oluştur\n",
        "final_audio_files = sorted(list(set(extracted_audio_files)))\n",
        "if final_audio_files:\n",
        "  print(\"\\nİnce ayar için kullanılacak son ses dosyaları:\")\n",
        "  for f_path in final_audio_files:\n",
        "    print(f\"  - {f_path}\")\n",
        "else:\n",
        "  print(\"\\nİnce ayar için işlenecek uygun formatta (.wav, .mp3) ses dosyası bulunamadı. Lütfen yüklemelerinizi kontrol edin.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "unique-data-preprocess-md"
      },
      "cell_type": "markdown",
      "source": [
        "## Adım 3: Veri Ön İşleme\n",
        "\n",
        "Bu adımda, bir önceki adımda belirlenen ses dosyaları ince ayar için uygun formata getirilecektir:\n",
        "1.  **Yeniden Örnekleme ve Kanal Ayarlama:** Tüm ses dosyaları SpectroStream kodeğinin beklediği örnekleme hızına (48kHz) ve kanal sayısına (stereo) dönüştürülür.\n",
        "2.  **Parçalara Bölme (Chunking):** Ses dosyaları, belirlenen uzunlukta daha kısa parçalara (chunk) bölünür. Bu, modelin sabit uzunlukta girdilerle çalışmasını sağlar.\n",
        "3.  **Belirteçleme (Tokenization):** Her bir ses parçası, SpectroStream kodeği kullanılarak ses belirteçlerine (audio tokens) dönüştürülür. Bu belirteçler, LLM'in anlayabileceği ayrık temsillerdir."
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "unique-preprocess-audio-code"
      },
      "cell_type": "code",
      "source": [
        "# @title Ses Dosyalarını Ön İşleme Hücresi\n",
        "\n",
        "#@markdown ### Ön İşleme Parametreleri:\n",
        "TARGET_SAMPLE_RATE = 48000  # SpectroStream'in beklediği örnekleme hızı (Hz)\n",
        "TARGET_CHANNELS = 2       # SpectroStream'in beklediği kanal sayısı (1=mono, 2=stereo)\n",
        "#@markdown --- \n",
        "#@markdown ### Parça Ayarları:\n",
        "CHUNK_DURATION_SECONDS = 2.0 #@param {type:\"number\", min:0.5, max:10, step:0.1}\n",
        "#@markdown Her bir ses parçasının saniye cinsinden uzunluğu. Modelin orijinal `chunk_length`'i (2.0s) ile aynı veya yakın olması genellikle iyi bir başlangıç noktasıdır.\n",
        "HOP_DURATION_SECONDS = 2.0 #@param {type:\"number\", min:0.1, max:10, step:0.1}\n",
        "#@markdown Parçalar arasındaki atlama süresi (saniye). \n",
        "#@markdown *   Eğer `HOP_DURATION_SECONDS == CHUNK_DURATION_SECONDS` ise, parçalar arasında overlap olmaz (bağımsız parçalar).\n",
        "#@markdown *   Eğer `HOP_DURATION_SECONDS < CHUNK_DURATION_SECONDS` ise, parçalar arasında overlap olur (veri artırma tekniği olarak kullanılabilir).\n",
        "#@markdown *   Overlap kullanmak, eğitim veri miktarını artırsa da, ince ayar stratejisini ve hedeflerin nasıl oluşturulacağını etkileyebilir.\n",
        "\n",
        "processed_tokens_list = [] # İşlenmiş tüm parçaların belirteçlerini tutacak liste\n",
        "failed_files_preprocessing = [] # Ön işleme sırasında hata veren dosyalar\n",
        "\n",
        "if 'final_audio_files' not in locals() or not final_audio_files:\n",
        "  print(\"HATA: İşlenecek ses dosyası listesi bulunamadı. Lütfen Adım 2'yi çalıştırarak ses dosyalarınızı yükleyin.\")\n",
        "else:\n",
        "  if MRT is None or codec is None:\n",
        "    print(\"HATA: Magenta RT modeli (MRT) veya SpectroStream kodeği (codec) yüklenemedi. Lütfen Adım 1'deki başlatma hücresini kontrol edin.\")\n",
        "  else:\n",
        "    chunk_length_samples = int(CHUNK_DURATION_SECONDS * TARGET_SAMPLE_RATE)\n",
        "    hop_length_samples = int(HOP_DURATION_SECONDS * TARGET_SAMPLE_RATE)\n",
        "    min_samples_for_one_chunk = chunk_length_samples\n",
        "\n",
        "    print(f\"Toplam {len(final_audio_files)} adet ses dosyası ön işleme için sırada...\")\n",
        "    for i, audio_filepath in enumerate(final_audio_files):\n",
        "      print(f\"\\n[{i+1}/{len(final_audio_files)}] İşleniyor: {audio_filepath}\")\n",
        "      try:\n",
        "        # Ses dosyasını yükle (orijinal sr ve kanallarla)\n",
        "        y, sr = librosa.load(audio_filepath, sr=None, mono=False) \n",
        "        current_channels = y.ndim if y.ndim == 1 else y.shape[0] if y.shape[0] < y.shape[1] else y.shape[1]\n",
        "        current_samples = y.shape[0] if y.ndim == 1 else y.shape[1] if y.shape[0] < y.shape[1] else y.shape[0]\n",
        "        print(f\"  Orijinal: {sr} Hz, {current_samples} örnek, {current_channels} kanal\")\n",
        "\n",
        "        # Librosa bazen (kanal, örnek) şeklinde yükleyebilir, (örnek, kanal) formatına getir\n",
        "        if y.ndim == 2 and y.shape[0] < y.shape[1] and y.shape[0] in [1,2]: # (kanal, örnek) ise transpoze et\n",
        "            y = y.T\n",
        "            print(\"  Format (örnek, kanal) olarak ayarlandı.\")\n",
        "\n",
        "        # Örnekleme hızını hedef hıza dönüştür\n",
        "        if sr != TARGET_SAMPLE_RATE:\n",
        "          y = librosa.resample(y, orig_sr=sr, target_sr=TARGET_SAMPLE_RATE, axis=0) # axis=0 zaman ekseni\n",
        "          print(f\"  {TARGET_SAMPLE_RATE} Hz'e yeniden örneklendi.\")\n",
        "        \n",
        "        # Kanal sayısını hedef kanal sayısına (stereo) dönüştür\n",
        "        if y.ndim == 1: # Mono ise stereo yap\n",
        "          y = np.stack([y, y], axis=-1)\n",
        "          print(\"  Mono'dan Stereo'ya dönüştürüldü (kopyalayarak).\")\n",
        "        elif y.shape[1] != TARGET_CHANNELS:\n",
        "          print(f\"  Uyarı: Beklenmedik kanal sayısı ({y.shape[1]}). Stereo'ya dönüştürme denenecek.\")\n",
        "          if y.shape[1] > TARGET_CHANNELS: # Fazla kanal varsa ilk ikisini al\n",
        "            y = y[:, :TARGET_CHANNELS]\n",
        "          else: # Tekrar mono durumu (çok kanallı ama TARGET_CHANNELS'dan az ise, bu durum nadirdir)\n",
        "            y_mono = librosa.to_mono(y.T) # Önce mono yap\n",
        "            y = np.stack([y_mono, y_mono], axis=-1) # Sonra stereo yap\n",
        "          print(f\"  Stereo'ya dönüştürüldü (son kanal sayısı: {y.shape[1]}).\")\n",
        "        \n",
        "        num_samples = y.shape[0]\n",
        "        if num_samples < min_samples_for_one_chunk:\n",
        "          print(f\"  UYARI: Dosya çok kısa ({num_samples} örnek), en az {min_samples_for_one_chunk} örnek ({CHUNK_DURATION_SECONDS}s) gerekli. Bu dosya atlanıyor.\")\n",
        "          failed_files_preprocessing.append(audio_filepath)\n",
        "          continue\n",
        "        \n",
        "        print(f\"  Son format (işleme için): {TARGET_SAMPLE_RATE} Hz, {y.shape[0]} örnek, {y.shape[1]} kanal\")\n",
        "\n",
        "        # Parçalara böl ve belirteçle\n",
        "        file_tokens_count = 0\n",
        "        for start_sample in range(0, num_samples - chunk_length_samples + 1, hop_length_samples):\n",
        "          end_sample = start_sample + chunk_length_samples\n",
        "          chunk_samples = y[start_sample:end_sample, :] # (chunk_length_samples, TARGET_CHANNELS)\n",
        "          \n",
        "          # magenta_rt.audio.Waveform nesnesi oluştur (float32 bekler)\n",
        "          waveform_chunk = audio.Waveform(samples=chunk_samples.astype(np.float32), sample_rate=TARGET_SAMPLE_RATE)\n",
        "          \n",
        "          # SpectroStream ile belirteçle\n",
        "          tokens = codec.encode(waveform_chunk) # Çıktı: (çerçeve_sayısı, tam_rvq_derinliği)\n",
        "          \n",
        "          # Eğitim için LLM'in beklediği RVQ derinliğine (decoder_codec_rvq_depth) indirgeyelim.\n",
        "          # SpectroStream.encode() tam derinliği (örn. 64) döndürür.\n",
        "          # LLM ise daha azını (örn. 16) kullanır.\n",
        "          tokens_for_llm_training = tokens[:, :MRT.config.decoder_codec_rvq_depth]\n",
        "          processed_tokens_list.append(tokens_for_llm_training)\n",
        "          file_tokens_count += 1\n",
        "        \n",
        "        if file_tokens_count > 0:\n",
        "            print(f\"  Dosyadan {file_tokens_count} adet {CHUNK_DURATION_SECONDS}sn'lik parça işlendi ve '{MRT.config.decoder_codec_rvq_depth}' RVQ derinliğinde belirteçlendi.\")\n",
        "        else:\n",
        "            print(f\"  Dosyadan hiç tam parça çıkarılamadı (uzunluk: {num_samples} örnek, gereken: {chunk_length_samples} örnek). Atlanıyor.\")\n",
        "            failed_files_preprocessing.append(audio_filepath)\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"  HATA: '{audio_filepath}' işlenirken bir sorun oluştu: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        failed_files_preprocessing.append(audio_filepath)\n",
        "    \n",
        "    print(f\"\\n--- Ön İşleme Tamamlandı ---\")\n",
        "    print(f\"Toplam {len(processed_tokens_list)} adet ses parçası ({CHUNK_DURATION_SECONDS}sn her biri) başarıyla işlendi ve belirteçlendi.\")\n",
        "    if failed_files_preprocessing:\n",
        "      print(\"Aşağıdaki dosyalar ön işleme sırasında hatalarla karşılaştı veya atlandı:\")\n",
        "      for f_err in list(set(failed_files_preprocessing)):\n",
        "        print(f\"  - {f_err}\")\n",
        "\n",
        "if processed_tokens_list:\n",
        "  print(f\"\\nİlk işlenen parçanın belirteç boyutu: {processed_tokens_list[0].shape}\")\n",
        "  expected_frames = int(CHUNK_DURATION_SECONDS * codec.config.frame_rate)\n",
        "  actual_frames = processed_tokens_list[0].shape[0]\n",
        "  actual_depth = processed_tokens_list[0].shape[1]\n",
        "  print(f\"  Beklenen çerçeve sayısı (her parça için): ~{expected_frames}, Alınan: {actual_frames}\")\n",
        "  print(f\"  Alınan (ve eğitime verilecek) RVQ derinliği: {actual_depth} (Bu, LLM'in `decoder_codec_rvq_depth` değeri olan {MRT.config.decoder_codec_rvq_depth} olmalıdır)\")\n",
        "  if actual_depth != MRT.config.decoder_codec_rvq_depth:\n",
        "      print(f\"  UYARI: Belirteçlerin RVQ derinliği ({actual_depth}) LLM'in beklediği derinlikten ({MRT.config.decoder_codec_rvq_depth}) farklı! Bu durum eğitimde sorunlara yol açabilir.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "unique-model-optimizer-md"
      },
      "cell_type": "markdown",
      "source": [
        "## Adım 4: İnce Ayar Modeli ve Optimizatörün Tanımlanması (Kavramsal)\n",
        "\n",
        "Bu adımda, ince ayar yapılacak modeli (Magenta RT'nin LLM kısmı) ve eğitim için kullanılacak optimizatörü tanımlayacağız.\n",
        "\n",
        "**ÖNEMLİ UYARI:** Magenta RT'nin altında yatan T5X modelinin parametrelerine ve eğitim fonksiyonlarına (Flax `apply_fn`) doğrudan erişmek ve bunları standart bir JAX/Flax eğitim döngüsüne entegre etmek karmaşıktır. `MagentaRT` sınıfı, çıkarım (inference) için optimize edilmiştir ve eğitim için doğrudan bir arayüz sunmayabilir. \n",
        "Bu nedenle, bu bölümdeki kodlar **büyük ölçüde kavramsal ve yer tutucudur.** Gerçek bir ince ayar için:\n",
        "1.  T5X kütüphanesinin kendi ince ayar ve eğitim komut dosyalarını kullanmak (bu Colab'ın kapsamı dışındadır).\n",
        "2.  Magenta RT'nin LLM modelini T5X'ten çıkarıp, eğitilebilir bir Flax modeline dönüştürmek ve bu model için `TrainState` oluşturmak gerekebilir. Bu, model mimarisinin ve ağırlık yükleme mekanizmalarının derinlemesine anlaşılmasını gerektirir.\n",
        "\n",
        "Aşağıdaki hücreler, eğer böyle bir erişim mümkün olsaydı nasıl bir yol izlenebileceğine dair bir fikir vermek amacıyla sunulmuştur."
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "unique-define-model-opt-code"
      },
      "cell_type": "code",
      "source": [
        "# @title Model, Optimizatör ve Kayıp Fonksiyonunu Tanımlama (Kavramsal Kod)\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax # JAX için popüler bir optimizasyon kütüphanesi\n",
        "from flax.training import train_state  # Eğitim durumunu yönetmek için\n",
        "# from flax.core import freeze, unfreeze # Parametreleri dondurmak/çözmek için gerekebilir\n",
        "\n",
        "#@markdown ### İnce Ayar Parametreleri (Kavramsal):\n",
        "LEARNING_RATE = 1e-5 #@param {type:\"number\"}\n",
        "#@markdown Düşük bir öğrenme hızı genellikle ince ayar için daha güvenlidir.\n",
        "WARMUP_STEPS = 50 #@param {type:\"integer\"}\n",
        "TRAIN_BATCH_SIZE = 2 #@param {type:\"integer\"}\n",
        "#@markdown `TRAIN_BATCH_SIZE` TPU üzerinde çalışırken genellikle TPU çekirdek sayısının (örn. 8) katları veya bölenleri olarak ayarlanır.\n",
        "#@markdown Ancak, bellek kısıtlamaları nedeniyle daha küçük tutulabilir.\n",
        "\n",
        "model_params_for_fine_tuning = None\n",
        "model_apply_fn_for_fine_tuning = None\n",
        "tx = None # Optimizatör\n",
        "current_train_state = None # Flax TrainState\n",
        "\n",
        "if MRT is None:\n",
        "  print(\"HATA: Magenta RT modeli (MRT) yüklenemedi. Lütfen Adım 1'i kontrol edin.\")\n",
        "else:\n",
        "  print(\"UYARI: Bu bölümdeki model ve optimizatör tanımlaması, Magenta RT'nin iç yapısına\\\n",
        "        erişimin mümkün olduğu varsayımına dayanmaktadır ve büyük ölçüde spekülatiftir.\")\n",
        "\n",
        "  # Kavramsal Adım 1: MRT._llm içinden T5X modelinin parametrelerini (ağırlıklarını) çıkarmak.\n",
        "  # Bu, MRT._llm nesnesinin yapısına bağlıdır. `MRT._llm._model.get_variables()` gibi bir şey olabilir.\n",
        "  try:\n",
        "    # `MRT._llm` bir callable. Bu callable'ın `model` veya `variables` gibi bir özelliği olabilir.\n",
        "    # Bu, `magenta_rt.depthformer.model.InteractiveModel` sınıfının iç yapısına bağlıdır.\n",
        "    # Eğer T5X `CheckpointContent` nesnesine benzer bir yapı varsa, oradan değişkenler alınabilir.\n",
        "    # Bu sadece bir tahmin:\n",
        "    if hasattr(MRT, '_llm') and hasattr(MRT._llm, '_model_variables'):\n",
        "        model_params_for_fine_tuning = MRT._llm._model_variables\n",
        "        # Parametrelerin eğitilebilir olması için 'unfreeze' gerekebilir, eğer Flax'ta 'frozen dict' ise.\n",
        "        # model_params_for_fine_tuning = unfreeze(model_params_for_fine_tuning)\n",
        "        print(\"Model parametreleri (kavramsal olarak) alındı.\")\n",
        "    else:\n",
        "        print(\"UYARI: MRT._llm._model_variables bulunamadı. Parametreler alınamadı.\")\n",
        "\n",
        "    # Kavramsal Adım 2: Modelin `apply_fn`'sini (ileri yayılım fonksiyonu) almak.\n",
        "    # Bu da `MRT._llm`'in veya içindeki T5X modelinin bir özelliği olmalıdır.\n",
        "    # `MRT._llm._predict_fn` çıkarım için kullanılır, eğitim için farklı bir `apply_fn` gerekebilir.\n",
        "    # Veya `MRT._llm.model.apply` gibi bir şey olabilir.\n",
        "    if hasattr(MRT, '_llm') and hasattr(MRT._llm, '_predict_fn'): #veya ._model.apply\n",
        "        # `_predict_fn` genellikle eğitim için uygun değildir (dropout vs. kapalı olabilir).\n",
        "        # Gerçek bir T5X model nesnesinin `apply` metoduna ihtiyacımız var.\n",
        "        # Bu Colab'da bu fonksiyonu elde etmek zor olduğundan, yer tutucu bırakıyoruz.\n",
        "        model_apply_fn_for_fine_tuning = None # Yer tutucu\n",
        "        print(\"Model apply_fn (kavramsal olarak) referans alındı (ancak eğitim için uygun olmayabilir).\")\n",
        "        if model_apply_fn_for_fine_tuning is None:\n",
        "            print(\"UYARI: Eğitim için uygun bir model_apply_fn bulunamadı.\")\n",
        "  except Exception as e:\n",
        "    print(f\"Model parametrelerini/apply_fn'yi alırken hata: {e}\")\n",
        "\n",
        "  if model_params_for_fine_tuning is not None and model_apply_fn_for_fine_tuning is not None:\n",
        "    print(\"Optimizatör ve Eğitim Durumu oluşturuluyor...\")\n",
        "    lr_schedule = optax.warmup_cosine_decay_schedule(\n",
        "        init_value=0.0, peak_value=LEARNING_RATE, warmup_steps=WARMUP_STEPS,\n",
        "        decay_steps=10000, end_value=LEARNING_RATE/10 # decay_steps toplam adım sayısına göre ayarlanmalı\n",
        "    )\n",
        "    tx = optax.adamw(learning_rate=lr_schedule)\n",
        "    \n",
        "    try:\n",
        "      current_train_state = train_state.TrainState.create(\n",
        "          apply_fn=model_apply_fn_for_fine_tuning, \n",
        "          params=model_params_for_fine_tuning, \n",
        "          tx=tx\n",
        "      )\n",
        "      print(\"Flax TrainState başarıyla oluşturuldu.\")\n",
        "    except Exception as e:\n",
        "      print(f\"Flax TrainState oluşturulurken hata: {e}\")\n",
        "      print(\"Bu genellikle `apply_fn`'nin veya `params`'ın beklenen formatta olmamasından kaynaklanır.\")\n",
        "      current_train_state = None # Başarısız olduysa sıfırla\n",
        "  else:\n",
        "    print(\"Model parametreleri veya apply_fn eksik olduğu için optimizatör ve eğitim durumu oluşturulamadı.\")\n",
        "    # Optimizatörü yine de tanımlayalım ki bir sonraki hücre tamamen çökmesin (ama TrainState olmayacak)\n",
        "    lr_schedule = optax.warmup_cosine_decay_schedule(\n",
        "        init_value=0.0, peak_value=LEARNING_RATE, warmup_steps=WARMUP_STEPS,\n",
        "        decay_steps=10000, end_value=LEARNING_RATE/10\n",
        "    )\n",
        "    tx = optax.adamw(learning_rate=lr_schedule)\n",
        "    print(\"Optimizatör (tx) tanımlandı, ancak TrainState oluşturulamadı.\")\n",
        "\n",
        "# Kayıp Fonksiyonu (Cross-entropy)\n",
        "# Bu fonksiyon, modelin logitlerini ve gerçek hedef belirteçlerini alır.\n",
        "def compute_loss_for_training(logits, targets, vocab_size_for_loss_fn):\n",
        "  # `targets` (batch_size, seq_len)\n",
        "  # `logits` (batch_size, seq_len, vocab_size)\n",
        "  one_hot_targets = jax.nn.one_hot(targets, num_classes=vocab_size_for_loss_fn)\n",
        "  # Genellikle kayıp hesaplanırken PAD tokenları maskelenir.\n",
        "  # Bu örnekte basitlik adına maskeleme eklenmemiştir.\n",
        "  loss = optax.softmax_cross_entropy(logits=logits, labels=one_hot_targets).mean()\n",
        "  return loss\n",
        "\n",
        "print(\"Kayıp fonksiyonu (compute_loss_for_training) tanımlandı.\")\n",
        "\n",
        "if current_train_state is None:\n",
        "    print(\"\\nUYARI: Eğitim durumu (current_train_state) düzgün bir şekilde başlatılamadı. Eğitim adımı çalışmayacaktır.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "unique-training-loop-md"
      },
      "cell_type": "markdown",
      "source": [
        "## Adım 5: Eğitim Döngüsü (Kavramsal)\n",
        "\n",
        "Bu adımda, hazırlanan veriler üzerinde modelin ince ayarını gerçekleştirecek eğitim döngüsünü tanımlayacağız.\n",
        "\n",
        "**YİNE UYARI:** Bu bölüm, Adım 4'teki `current_train_state`'in (Flax `TrainState` içeren model parametreleri, `apply_fn` ve optimizatör durumu) başarıyla oluşturulduğu varsayımına dayanır. Eğer `current_train_state` `None` ise, bu hücredeki eğitim döngüsü **çalışmayacaktır** ve sadece bir şablon olarak görev görecektir."
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "unique-training-loop-code"
      },
      "cell_type": "code",
      "source": [
        "# @title Eğitim Döngüsü Hücresi (Kavramsal Kod)\n",
        "import time\n",
        "\n",
        "#@markdown ### Eğitim Parametreleri:\n",
        "NUM_EPOCHS = 1 #@param {type:\"integer\", min:1, max:100}\n",
        "REPORT_INTERVAL_STEPS = 10 #@param {type:\"integer\", min:1, max:1000}\n",
        "#@markdown İnce ayar için genellikle az sayıda epoch yeterlidir.\n",
        "\n",
        "def prepare_training_data_iterator(tokens_list_for_epoch, batch_size_for_iterator, prng_key_for_iterator):\n",
        "    \"\"\"Veri kümesini karıştırır ve batch'ler halinde yield eder.\"\"\"\n",
        "    num_samples_total = len(tokens_list_for_epoch)\n",
        "    if num_samples_total == 0:\n",
        "        yield None, None # Veri yoksa None döndür\n",
        "        return\n",
        "\n",
        "    # Her epoch için veriyi karıştır\n",
        "    perm = jax.random.permutation(prng_key_for_iterator, num_samples_total)\n",
        "    shuffled_tokens_list = [tokens_list_for_epoch[i] for i in perm]\n",
        "\n",
        "    for i in range(0, num_samples_total, batch_size_for_iterator):\n",
        "        batch_tokens_raw = shuffled_tokens_list[i:i + batch_size_for_iterator]\n",
        "        if not batch_tokens_raw: continue\n",
        "\n",
        "        # Bu fonksiyon, Adım 4'teki prepare_training_batch'e benzer şekilde batch'i LLM formatına getirmeli.\n",
        "        # Yani, RVQ derinliğini ayarlama, LLM vocab'ına dönüştürme ve padding.\n",
        "        # Şimdilik, processed_tokens_list'in zaten doğru RVQ derinliğinde (decoder_codec_rvq_depth)\n",
        "        # ve LLM vocab'ına dönüştürülmeye hazır olduğunu varsayıyoruz (Adım 3'te yapıldı).\n",
        "        \n",
        "        batch_input_llm_tokens_for_iter = []\n",
        "        # İnce ayarda, genellikle `decoder_input_tokens` ve `decoder_target_tokens` olur.\n",
        "        # `decoder_input_tokens` genellikle `[BOS, t1, t2, ..., tn]`\n",
        "        # `decoder_target_tokens` ise `[t1, t2, ..., tn, EOS]` şeklindedir.\n",
        "        # Bizim `processed_tokens_list`'imizdeki her eleman bir parça (chunk) belirteci.\n",
        "        # Bu belirteçleri LLM kelime dağarcığına çevirmemiz gerekiyor.\n",
        "\n",
        "        max_seq_len_this_batch = 0\n",
        "        if batch_tokens_raw:\n",
        "            max_seq_len_this_batch = max(raw_tok.shape[0] * raw_tok.shape[1] for raw_tok in batch_tokens_raw)\n",
        "\n",
        "        for raw_tokens_chunk in batch_tokens_raw: # raw_tokens_chunk: (frames, rvq_depth)\n",
        "            # RVQ derinliği Adım 3'te zaten MRT.config.decoder_codec_rvq_depth'e ayarlandı.\n",
        "            llm_tokens_flat = utils.rvq_to_llm(\n",
        "                raw_tokens_chunk, # Zaten doğru derinlikte olmalı\n",
        "                MRT.config.codec_rvq_codebook_size,\n",
        "                MRT.config.vocab_codec_offset\n",
        "            ).reshape(-1) # (seq_len * depth) -> (total_seq_len,)\n",
        "            \n",
        "            # Sabit dizi uzunluğuna padding (max_seq_len_this_batch'e göre)\n",
        "            # PAD token ID'si MRT.config.vocab_pad_token (genellikle 0)\n",
        "            pad_amount = max_seq_len_this_batch - llm_tokens_flat.shape[0]\n",
        "            padded_llm_tokens = jnp.pad(llm_tokens_flat, (0, pad_amount), constant_values=MRT.config.vocab_pad_token)\n",
        "            batch_input_llm_tokens_for_iter.append(padded_llm_tokens)\n",
        "\n",
        "        if not batch_input_llm_tokens_for_iter:\n",
        "            yield None, None\n",
        "            continue\n",
        "\n",
        "        final_batch_inputs = jnp.stack(batch_input_llm_tokens_for_iter)\n",
        "        # Hedefler, girdilerin bir sonraki token'ı olacak şekilde ayarlanır (sağa kaydırılmış).\n",
        "        # Ve son token PAD ile değiştirilir.\n",
        "        final_batch_targets = jnp.pad(final_batch_inputs[:, 1:], ((0,0), (0,1)), constant_values=MRT.config.vocab_pad_token)\n",
        "        \n",
        "        yield final_batch_inputs, final_batch_targets\n",
        "\n",
        "# Eğitim adımı fonksiyonu (JIT için derlenebilir)\n",
        "@jax.jit\n",
        "def perform_train_step(current_state_in_jit, batch_decoder_input_tokens, batch_decoder_target_tokens):\n",
        "    \"\"\"Tek bir eğitim adımını gerçekleştirir.\"\"\"\n",
        "    def loss_calculation_fn(params_in_loss_fn):\n",
        "        # Bu `apply_fn` çağrısı, modelin gerçek arayüzüne göre ayarlanmalıdır.\n",
        "        # `MRT._llm` veya ondan türetilen Flax modelinin `apply` metodu olmalı.\n",
        "        # Girdiler: {'params': params}, decoder_input_tokens=batch_decoder_input_tokens, training=True\n",
        "        # Çıktı: logits (batch_size, seq_len, vocab_size)\n",
        "        \n",
        "        # ** YER TUTUCU / KAVRAMSAL ÇAĞRI **\n",
        "        # Bu, `current_state_in_jit.apply_fn`'nin doğru şekilde tanımlandığını varsayar.\n",
        "        # Gerçek T5X modeli, sadece decoder tokenları değil, encoder çıktılarını da bekleyebilir.\n",
        "        # Bu durumda, `batch_encoder_input_tokens` ve `enable_dropout` gibi ek argümanlar gerekebilir.\n",
        "        # Bu örnekte, `apply_fn`'in sadece `decoder_input_tokens` ve `training` flag'i aldığını varsayıyoruz.\n",
        "        logits = current_state_in_jit.apply_fn(\n",
        "            {'params': params_in_loss_fn}, \n",
        "            decoder_input_tokens=batch_decoder_input_tokens, \n",
        "            # encoder_input_tokens=... (eğer gerekliyse, dummy veya gerçek sağlanmalı)\n",
        "            training=True # Dropout vb. aktif olması için\n",
        "        )\n",
        "        \n",
        "        # Gerçek kelime dağarcığı boyutunu logit'lerden al\n",
        "        actual_vocab_size = logits.shape[-1]\n",
        "        loss = compute_loss_for_training(logits, batch_decoder_target_tokens, actual_vocab_size)\n",
        "        return loss, logits # Kaybı ve logitleri döndür (logitler metrikler için kullanılabilir)\n",
        "\n",
        "    # Gradyanları hesapla\n",
        "    grad_calculation_fn = jax.value_and_grad(loss_calculation_fn, has_aux=True)\n",
        "    (loss_value, _), grads = grad_calculation_fn(current_state_in_jit.params)\n",
        "    \n",
        "    # Gradyanları uygula ve yeni state'i al\n",
        "    new_state_after_apply = current_state_in_jit.apply_gradients(grads=grads)\n",
        "    return new_state_after_apply, loss_value\n",
        "\n",
        "\n",
        "if 'processed_tokens_list' not in locals() or not processed_tokens_list:\n",
        "    print(\"HATA: İşlenmiş veri (processed_tokens_list) bulunamadı. Lütfen Adım 3'ü çalıştırın.\")\n",
        "elif 'current_train_state' not in locals() or current_train_state is None:\n",
        "    print(\"HATA: Model eğitim durumu (current_train_state) başlatılamadı. Lütfen Adım 4'ü kontrol edin.\")\n",
        "    print(\"Bu genellikle, Magenta RT'nin LLM'inin parametrelerine ve/veya eğitim için uygun bir `apply_fn`'sine erişilemediği anlamına gelir.\")\n",
        "    print(\"Bu Colab'da tam bir ince ayar döngüsü çalıştırmak için bu gereklidir ve şu anda bu desteklenmiyor olabilir.\")\n",
        "else:\n",
        "    print(\"Eğitim döngüsü başlıyor (Adım 4'teki UYARILARI dikkate alın)...\")\n",
        "    \n",
        "    total_steps_taken = current_train_state.step # Eğer daha önce eğitildiyse adımı koru\n",
        "    accumulated_loss_for_report = 0.0\n",
        "    epoch_start_time = time.time()\n",
        "    prng_key_epoch_shuffling = jax.random.PRNGKey(42) # Her epoch için veri karıştırma anahtarı\n",
        "\n",
        "    try:\n",
        "      for epoch in range(NUM_EPOCHS):\n",
        "          print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
        "          prng_key_epoch_shuffling, current_epoch_shuffle_key = jax.random.split(prng_key_epoch_shuffling)\n",
        "          \n",
        "          batch_iterator = prepare_training_data_iterator(processed_tokens_list, TRAIN_BATCH_SIZE, current_epoch_shuffle_key)\n",
        "          \n",
        "          step_in_epoch = 0\n",
        "          for batch_inputs, batch_targets in batch_iterator:\n",
        "              if batch_inputs is None or batch_targets is None:\n",
        "                  if step_in_epoch == 0: print(\"  Bu epoch için veri bulunamadı veya batch oluşturulamadı.\")\n",
        "                  break # Iterator bitti veya hata oluştu\n",
        "              \n",
        "              # Eğitim adımını JIT ile derlenmiş fonksiyonu kullanarak çalıştır\n",
        "              current_train_state, loss_val = perform_train_step(current_train_state, batch_inputs, batch_targets)\n",
        "              accumulated_loss_for_report += loss_val.item()\n",
        "              total_steps_taken += 1\n",
        "              step_in_epoch += 1\n",
        "\n",
        "              if total_steps_taken % REPORT_INTERVAL_STEPS == 0 and total_steps_taken > 0:\n",
        "                  avg_loss_since_last_report = accumulated_loss_for_report / (REPORT_INTERVAL_STEPS if step_in_epoch >= REPORT_INTERVAL_STEPS else step_in_epoch % REPORT_INTERVAL_STEPS)\n",
        "                  current_epoch_time = time.time() - epoch_start_time\n",
        "                  print(f\"  Epoch: {epoch+1}, Adım: {total_steps_taken}, Ortalama Kayıp (son {REPORT_INTERVAL_STEPS} adım): {avg_loss_since_last_report:.4f}, Epoch Süresi: {current_epoch_time:.2f}s\")\n",
        "                  accumulated_loss_for_report = 0.0\n",
        "          \n",
        "          print(f\"Epoch {epoch + 1} tamamlandı. Toplam {step_in_epoch} batch işlendi.\")\n",
        "          epoch_start_time = time.time() # Sonraki epoch için zamanı sıfırla\n",
        "\n",
        "    except NotImplementedError as nie:\n",
        "        print(f\"EĞİTİM DURDURULDU: {nie}\")\n",
        "        print(\"Lütfen Adım 4'teki model ve optimizatör tanımlamalarını ve `perform_train_step` içindeki `apply_fn` çağrısını kontrol edin.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Eğitim sırasında beklenmedik bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        print(f\"--- Eğitim Döngüsü Sonlandı ---\")\n",
        "        if total_steps_taken > (current_train_state.step if hasattr(current_train_state, 'step') and current_train_state.step is not None else 0) :\n",
        "            print(f\"Toplam {total_steps_taken} eğitim adımı atıldı.\")\n",
        "            # Son model state'i globalde güncelleyelim ki kaydedilebilsin\n",
        "            # (Eğer current_train_state bu scope'ta güncellenmiyorsa, global bir değişkene atamak gerekebilir)\n",
        "            # Ancak JAX'ta state genellikle fonksiyonlardan döndürülür.\n",
        "            # Bu Colab yapısında, `current_train_state` zaten en dış scope'ta.\n",
        "            print(\"Son model durumu (current_train_state) güncellendi.\")\n",
        "        else:\n",
        "            print(\"Hiç (yeni) eğitim adımı atılmadı. Lütfen veri ve model yapılandırmasını kontrol edin.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "unique-save-model-md"
      },
      "cell_type": "markdown",
      "source": [
        "## Adım 6: İnce Ayarlanmış Modelin Kaydedilmesi ve İndirilmesi (Kavramsal)\n",
        "\n",
        "Eğitim döngüsü tamamlandıktan sonra (veya istediğiniz bir noktada), ince ayarlanmış modelin ağırlıklarını kaydedebilir ve daha sonra kullanmak üzere indirebilirsiniz.\n",
        "\n",
        "**YİNE UYARI:** Bu bölüm, `current_train_state`'in (eğitilmiş parametreleri içeren Flax `TrainState`) Adım 4 ve 5'te düzgün bir şekilde elde edildiği ve güncellendiği varsayımına dayanır. Eğer bu state mevcut değilse veya geçerli değilse, kaydetme işlemi **başarısız olacaktır**."
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "unique-save-model-code"
      },
      "cell_type": "code",
      "source": [
        "# @title Modeli Kaydetme ve İndirme Hücresi (Kavramsal Kod)\n",
        "from flax.training import checkpoints # Flax'in checkpoint yardımcıları\n",
        "import datetime\n",
        "import shutil\n",
        "\n",
        "#@markdown ### Kaydetme Ayarları:\n",
        "FINETUNED_MODEL_DIR = \"fine_tuned_magenta_rt_checkpoint\" #@param {type:\"string\"}\n",
        "MODEL_FILENAME_PREFIX = \"finetuned_mrt_llm\" #@param {type:\"string\"}\n",
        "\n",
        "if 'current_train_state' not in locals() or current_train_state is None:\n",
        "  print(\"HATA: Kaydedilecek model eğitim durumu (current_train_state) bulunamadı veya geçerli değil.\")\n",
        "  print(\"Lütfen önceki adımların (özellikle Adım 4 ve 5) başarıyla tamamlandığından ve `current_train_state`'in güncellendiğinden emin olun.\")\n",
        "elif not hasattr(current_train_state, 'params') or not hasattr(current_train_state, 'step'):\n",
        "  print(\"HATA: `current_train_state` beklenen `params` veya `step` özelliklerine sahip değil. Kaydedilemiyor.\")\n",
        "  print(\"Bu, Adım 4'teki TrainState oluşturma işleminin başarısız olduğu anlamına gelebilir.\")\n",
        "else:\n",
        "  try:\n",
        "    if not os.path.exists(FINETUNED_MODEL_DIR):\n",
        "      os.makedirs(FINETUNED_MODEL_DIR)\n",
        "      print(f\"'{FINETUNED_MODEL_DIR}' dizini oluşturuldu.\")\n",
        "    \n",
        "    # Flax TrainState'i kaydetme\n",
        "    # `target` olarak tüm TrainState nesnesini veriyoruz, bu hem parametreleri hem de optimizatör durumunu içerir.\n",
        "    save_path = checkpoints.save_checkpoint(\n",
        "        ckpt_dir=FINETUNED_MODEL_DIR,\n",
        "        target=current_train_state, # Kaydedilecek nesne (Flax TrainState)\n",
        "        step=current_train_state.step, # TrainState'in içindeki adım sayısını kullan\n",
        "        prefix=MODEL_FILENAME_PREFIX + \"_\",\n",
        "        overwrite=True # Önceki aynı adımdaki checkpoint'lerin üzerine yaz\n",
        "    )\n",
        "    print(f\"Model eğitim durumu (checkpoint) başarıyla '{save_path}' olarak kaydedildi.\")\n",
        "\n",
        "    # Kaydedilen checkpoint dizinini sıkıştırıp indirme\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    # Checkpoint genellikle bir dizin olduğundan (örn: fine_tuned_magenta_rt_checkpoint/finetuned_mrt_llm_100)\n",
        "    # tüm FINETUNED_MODEL_DIR'i sıkıştırmak daha mantıklı.\n",
        "    zip_filename_base = f\"{FINETUNED_MODEL_DIR}_{timestamp}\"\n",
        "    zip_filepath = f\"{zip_filename_base}.zip\"\n",
        "    \n",
        "    print(f\"'{FINETUNED_MODEL_DIR}' dizini '{zip_filepath}' olarak sıkıştırılıyor...\")\n",
        "    shutil.make_archive(zip_filename_base, 'zip', FINETUNED_MODEL_DIR)\n",
        "\n",
        "    print(f\"Sıkıştırılmış model checkpoint'i '{zip_filepath}' indirilmeye hazır.\")\n",
        "    print(f\"Lütfen Colab'ın sol tarafındaki dosya gezgininden '{zip_filepath}' dosyasını bulun ve sağ tıklayıp indirin.\")\n",
        "    print(\"Alternatif olarak, bir sonraki hücreyi kullanarak indirmeyi deneyebilirsiniz (büyük dosyalar için zaman aşımına uğrayabilir).\")\n",
        "\n",
        "  except NotImplementedError as nie:\n",
        "      print(f\"Model kaydedilemedi veya sıkıştırılamadı: {nie}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Model kaydedilirken veya sıkıştırılırken bir hata oluştu: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "unique-download-explicit-code"
      },
      "cell_type": "code",
      "source": [
        "# @title Modeli İndirme Hücresi (Opsiyonel)\n",
        "#@markdown Yukarıdaki hücrede sıkıştırılan ZIP dosyasının adını buraya girin.\n",
        "#@markdown Örneğin: `fine_tuned_magenta_rt_checkpoint_20231027_103045.zip`\n",
        "FILE_TO_DOWNLOAD_USER_SPECIFIED = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if not FILE_TO_DOWNLOAD_USER_SPECIFIED:\n",
        "    print(\"Lütfen indirilecek ZIP dosyasının adını yukarıdaki alana girin.\")\n",
        "elif 'current_train_state' not in locals() or current_train_state is None or not hasattr(current_train_state, 'params'):\n",
        "    print(\"Model eğitim durumu düzgün bir şekilde başlatılmadığı veya eğitilmediği için indirme işlemi mantıklı değil.\")\n",
        "elif os.path.exists(FILE_TO_DOWNLOAD_USER_SPECIFIED):\n",
        "    try:\n",
        "        print(f\"'{FILE_TO_DOWNLOAD_USER_SPECIFIED}' indiriliyor...\")\n",
        "        files.download(FILE_TO_DOWNLOAD_USER_SPECIFIED)\n",
        "        print(\"İndirme isteği tarayıcınıza gönderildi. Lütfen tarayıcınızın indirme yöneticisini kontrol edin.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Dosya indirilirken bir hata oluştu: {e}.\")\n",
        "        print(\"Dosya çok büyükse bu Colab yöntemi zaman aşımına uğrayabilir.\")\n",
        "        print(\"Lütfen Colab'ın sol tarafındaki dosya gezgininden dosyayı manuel olarak indirmeyi deneyin.\")\n",
        "else:\n",
        "    print(f\"HATA: '{FILE_TO_DOWNLOAD_USER_SPECIFIED}' adlı dosya mevcut dizinde bulunamadı.\")\n",
        "    print(\"Lütfen dosya adının doğru olduğundan ve bir önceki hücrenin başarıyla çalıştığından emin olun.\")\n",
        "    print(f\"Mevcut dizindeki dosyalar ve klasörler: {os.listdir('.')}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "unique-conclusion-md"
      },
      "cell_type": "markdown",
      "source": [
        "## Adım 7: Sonuç ve Sonraki Adımlar\n",
        "\n",
        "Tebrikler! Bu not defterindeki adımları (kavramsal olanlar dahil) tamamladınız.\n",
        "\n",
        "**Özet:**\n",
        "*   Magenta RT ve bağımlılıklarını kurdunuz.\n",
        "*   İnce ayar için kendi ses verilerinizi yüklediniz ve ön işlediniz.\n",
        "*   Model tanımlama, optimizatör ve eğitim döngüsü adımlarının kavramsal bir uygulamasını gördünüz.\n",
        "*   İnce ayarlanmış modelinizi (kavramsal olarak) kaydetme ve indirme adımlarını incelediniz.\n",
        "\n",
        "**ÖNEMLİ HATIRLATMA:** Bu not defterindeki Adım 4 (Model Tanımlama) ve Adım 5 (Eğitim Döngüsü), Magenta RT'nin T5X tabanlı LLM'inin karmaşıklığı nedeniyle **büyük ölçüde kavramsal ve yer tutucudur.** Bu adımların tam olarak çalışır hale getirilmesi, T5X model mimarisine derinlemesine hakimiyet ve muhtemelen T5X'in kendi eğitim/ince ayar araçlarının kullanılmasını gerektirir. Bu Colab, bu sürecin genel akışını ve zorluklarını göstermeyi amaçlamaktadır.\n",
        "\n",
        "**Sonraki Adımlar (Eğer İnce Ayar Başarılı Olsaydı):**\n",
        "1.  **Modeli Yükleme:** Kaydettiğiniz ince ayarlanmış checkpoint'i kullanarak bir `MagentaRT` nesnesini yeniden başlatmanız gerekir. Bu, `system.MagentaRT` kurucusuna uygun `checkpoint_dir` parametresini vermeyi içerebilir.\n",
        "2.  **Test Etme:** İnce ayarlanmış modelin, orijinal modele kıyasla veya ince ayar verilerinize daha uygun çıktılar üretip üretmediğini test edin. Farklı istemler (prompts) kullanarak müzik üretin.\n",
        "3.  **Daha Fazla İyileştirme:** Eğitim parametrelerini (öğrenme hızı, epoch sayısı, batch boyutu), veri ön işleme adımlarını veya ince ayar stratejisini (örneğin, hangi katmanların eğitileceği) değiştirerek sonuçları iyileştirmeyi deneyebilirsiniz.\n",
        "\n",
        "Bu not defterinin, Magenta RT ile ince ayar sürecine bir giriş yapmanıza yardımcı olduğunu umuyoruz!"
      ]
    },
    {
      "metadata": {
        "id": "unique-testing-finetuned-md"
      },
      "cell_type": "markdown",
      "source": [
        "## Adım 8: İnce Ayarlanmış Modeli Test Etme (Kavramsal)\n",
        "\n",
        "Eğer Adım 4, 5 ve 6'daki ince ayar, model kaydetme ve yükleme işlemleri başarıyla tamamlanabilseydi, bu adımda ince ayarlanmış modelinizin performansını test edebilirdiniz.\n",
        "\n",
        "**Test Etme Adımları (Genel Fikir):**\n",
        "1.  **İnce Ayarlanmış Modeli Yükleme:** `MagentaRT` sistemini, kaydettiğiniz ince ayarlanmış checkpoint'i gösterecek şekilde başlatmanız gerekir. Bu, `system.MagentaRT` kurucusundaki `checkpoint_dir` argümanını kullanmayı içerebilir. `tag` argümanı, orijinal modelin boyutunu (base veya large) belirtmeye devam edebilirken, `checkpoint_dir` özel ağırlıklarınızı işaret eder.\n",
        "2.  **Müzik Üretme:** İnce ayar yaparken kullandığınız veri stiline benzer veya o stili çağrıştıran metin istemleri (prompts) kullanarak yeni müzik parçaları üretin.\n",
        "3.  **Karşılaştırma:**\n",
        "    *   İnce ayarlanmış modelin çıktılarını, **orijinal (ince ayar yapılmamış) Magenta RT modelinin** aynı istemlerle ürettiği çıktılarla karşılaştırın.\n",
        "    *   Çıktıların, ince ayar veri kümenizdeki müziğin karakteristik özelliklerini (tempo, armoni, ritim, enstrümantasyon vb.) ne kadar yansıttığını değerlendirin.\n",
        "    *   Modelin hala genel müzikal tutarlılığını koruyup korumadığını kontrol edin.\n",
        "\n",
        "**Aşağıdaki kod hücresi, bu test sürecinin nasıl görünebileceğine dair KAVRAMSAL bir örnektir.** Bu hücre, önceki adımların (özellikle `current_train_state` ve çalışan bir eğitim döngüsü) tam olarak işlevsel olduğunu varsayar, ki bu Colab'ın mevcut halinde durum böyle değildir."
      ]
    },
    {
      "metadata": {
        "cellView": "form",
        "id": "unique-test-finetuned-code"
      },
      "cell_type": "code",
      "source": [
        "# @title İnce Ayarlanmış Modeli Test Etme (Kavramsal Kod)\n",
        "import IPython.display as ipd\n",
        "\n",
        "#@markdown ### Test Parametreleri:\n",
        "FINETUNED_CHECKPOINT_PATH = \"fine_tuned_magenta_rt_checkpoint/\" #@param {type:\"string\"}\n",
        "#@markdown Yukarıda Adım 6'da modelinizi kaydettiğiniz dizinin yolu.\n",
        "TEST_PROMPT = \"ince ayar verilerimle ilişkili bir stil\" #@param {type:\"string\"}\n",
        "NUM_TEST_CHUNKS = 3 #@param {type:\"integer\"}\n",
        "\n",
        "mrt_finetuned = None\n",
        "can_test_finetuned_model = False\n",
        "\n",
        "print(\"KAVRAMSAL TEST ADIMI\")\n",
        "print(\"-------------------------\")\n",
        "if 'current_train_state' not in locals() or current_train_state is None or not hasattr(current_train_state, 'params'):\n",
        "    print(\"UYARI: Geçerli bir ince ayarlanmış model durumu (`current_train_state`) bulunmadığından bu test çalıştırılamaz.\")\n",
        "    print(\"Bu, Adım 4 ve 5'teki kavramsal adımların tam olarak uygulanamamasından kaynaklanmaktadır.\")\n",
        "elif not os.path.exists(FINETUNED_CHECKPOINT_PATH) or not os.listdir(FINETUNED_CHECKPOINT_PATH):\n",
        "    print(f\"UYARI: Belirtilen ince ayarlanmış checkpoint yolu '{FINETUNED_CHECKPOINT_PATH}' bulunamadı veya boş.\")\n",
        "    print(\"Lütfen Adım 6'nın (kavramsal kaydetme) en azından bir dosya oluşturduğundan emin olun.\")\n",
        "else:\n",
        "    print(\"İnce ayarlanmış Magenta RT modeli yüklenmeye çalışılıyor (kavramsal)...\")\n",
        "    try:\n",
        "        # Gerçek bir senaryoda, MagentaRT kurucusunun `checkpoint_dir` parametresini kullanarak\n",
        "        # T5X modelinin belirli bir checkpoint'ten yüklenmesini sağlamak gerekir.\n",
        "        # Bu, `magenta_rt.depthformer.model.load_pretrained_model` fonksiyonunun bu özelliği desteklemesini gerektirir.\n",
        "        # Mevcut `system.MagentaRT` sınıfı, `checkpoint_dir` argümanını doğrudan T5X yükleyicisine geçiriyor olabilir.\n",
        "        \n",
        "        mrt_finetuned = system.MagentaRT(\n",
        "            tag=MODEL_TAG,  # Orijinal modelin temel etiketini koru (base veya large)\n",
        "            device=\"tpu:v2-8\", \n",
        "            skip_cache=True, # Kontrol noktalarını yerel olarak aramaması için\n",
        "            lazy=False,      # Test için modeli hemen yükle\n",
        "            checkpoint_dir=FINETUNED_CHECKPOINT_PATH # İnce ayarlanmış checkpoint'in yolu\n",
        "        )\n",
        "        print(f\"'{FINETUNED_CHECKPOINT_PATH}' yolundan ince ayarlanmış model yüklendi (varsayımsal olarak).\")\n",
        "        can_test_finetuned_model = True\n",
        "    except Exception as e:\n",
        "        print(f\"İnce ayarlanmış model yüklenirken HATA oluştu: {e}\")\n",
        "        print(\"Bu, `system.MagentaRT`'nin `checkpoint_dir` ile özel ağırlıkları yükleme yeteneğine bağlıdır.\")\n",
        "        print(\"Mevcut Magenta RT sürümü bu işlevselliği tam olarak desteklemiyor olabilir.\")\n",
        "\n",
        "if can_test_finetuned_model and mrt_finetuned is not None:\n",
        "    print(f\"\\n'${TEST_PROMPT}' istemiyle ince ayarlanmış modelden müzik üretiliyor...\")\n",
        "    \n",
        "    try:\n",
        "        style_embedding_ft = mrt_finetuned.embed_style(TEST_PROMPT)\n",
        "        \n",
        "        chunks_ft = []\n",
        "        current_state_ft = None\n",
        "        for i in range(NUM_TEST_CHUNKS):\n",
        "            chunk_audio, current_state_ft = mrt_finetuned.generate_chunk(\n",
        "                state=current_state_ft,\n",
        "                style=style_embedding_ft,\n",
        "                seed=i # Her parça için farklı tohum\n",
        "            )\n",
        "            chunks_ft.append(chunk_audio)\n",
        "            print(f\"  Parça {i+1}/{NUM_TEST_CHUNKS} üretildi.\")\n",
        "        \n",
        "        if chunks_ft:\n",
        "            concatenated_audio_ft = audio.concatenate(\n",
        "                chunks_ft,\n",
        "                crossfade_time=mrt_finetuned.config.crossfade_length\n",
        "            )\n",
        "            print(\"Üretilen ses (ince ayarlanmış model):\")\n",
        "            ipd.display(ipd.Audio(concatenated_audio_ft.samples.T, rate=concatenated_audio_ft.sample_rate, normalize=False))\n",
        "        else:\n",
        "            print(\"İnce ayarlanmış modelden hiç parça üretilemedi.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"İnce ayarlanmış modelle müzik üretirken HATA oluştu: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(\"Bu, yüklenen checkpoint'in modelle uyumsuz olmasından veya çalışma zamanı hatalarından kaynaklanabilir.\")\n",
        "        \n",
        "    # Karşılaştırma için orijinal modeli de çalıştırabilirsiniz (eğer hala `MRT` değişkeninde yüklüyse)\n",
        "    if 'MRT' in locals() and MRT is not None and MRT != mrt_finetuned:\n",
        "        print(f\"\\nKarşılaştırma için orijinal modelden ('{TEST_PROMPT}') müzik üretiliyor...\")\n",
        "        try:\n",
        "            style_embedding_orig = MRT.embed_style(TEST_PROMPT)\n",
        "            chunks_orig = []\n",
        "            current_state_orig = None\n",
        "            for i in range(NUM_TEST_CHUNKS):\n",
        "                chunk_audio_orig, current_state_orig = MRT.generate_chunk(state=current_state_orig, style=style_embedding_orig, seed=i)\n",
        "                chunks_orig.append(chunk_audio_orig)\n",
        "            concatenated_audio_orig = audio.concatenate(chunks_orig, crossfade_time=MRT.config.crossfade_length)\n",
        "            print(\"Üretilen ses (orijinal model):\")\n",
        "            ipd.display(ipd.Audio(concatenated_audio_orig.samples.T, rate=concatenated_audio_orig.sample_rate, normalize=False))\n",
        "        except Exception as e:\n",
        "            print(f\"Orijinal modelle müzik üretirken HATA oluştu: {e}\")\n",
        "else:\n",
        "    if not can_test_finetuned_model:\n",
        "        print(\"\\nİnce ayarlanmış model yüklenemediği veya test için uygun olmadığı için test adımı atlandı.\")\n",
        "\n",
        "print(\"\\nKavramsal Test Adımı Tamamlandı.\")"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
